{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# домашняя работа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Теперь решаем задачу регрессии - предскажем цены на недвижимость. \n",
    "#    Использовать датасет \n",
    "#    https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data (train.csv)\n",
    "# 2. Данных немного, поэтому необходимо использовать 10-fold кросс-валидацию \n",
    "#    для оценки качества моделей\n",
    "# 3. Построить случайный лес, вывести важность признаков\n",
    "# 4. Обучить стекинг как минимум 3х моделей, использовать \n",
    "#    хотя бы 1 линейную модель и 1 нелинейную\n",
    "# 5. Для валидации модели 2-го уровня использовать \n",
    "#    отдельный hold-out датасет, как на занятии\n",
    "# 6. Показать, что использование ансамблей моделей действительно \n",
    "#    улучшает качество (стекинг vs другие модели сравнивать на hold-out)\n",
    "# 7. В качестве решения: Jupyter notebook с кодом, комментариями \n",
    "#    и графиками, ссылка на гитхаб\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 678.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнить средними значениеми\n",
    "def put_mean_to_na_param(dataset, list_columns):\n",
    "    for i in list_columns:\n",
    "        dataset[i].fillna(dataset[i].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнить значением\n",
    "def put_value_to_na_param(dataset, list_columns, value=0 ):\n",
    "    for i in list_columns:\n",
    "        dataset[i].fillna(value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнить самым распространенным значением\n",
    "def put_most_common_meaning_to_na_param(dataset, list_columns):\n",
    "    for i in list_columns:\n",
    "        dataset[i].fillna(dataset[i].value_counts()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполнить значения NaN значениеями из другой колонки\n",
    "def put_param_from_col_src_to_na_param(dataset, col_dest, col_src): \n",
    "    dataset[col_dest]=dataset.apply(lambda x: x[col_src] if x[col_dest] is not None else x[col_dest], axis=1 )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодировать nominal категориальную переменную с помощью \"one hot encoding\"  (используем реализацию из лекций)\n",
    "def get_one_hot(df, cols):\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df \n",
    "\n",
    "# Закодировать ordered категориальную переменную используя числовой порядок\n",
    "def get_ordered_col(dataset, col, dict_col_params):\n",
    "    \"\"\"\n",
    "    В функцию передается датасет, имя колонки и словарь {'значение_параметра_в_колонке': числовое_значение_для_замены }\n",
    "    \"\"\"\n",
    "    dataset[col + '_order'] = dataset.apply(lambda x: dict_col_params[x[col]],axis=1)\n",
    "    return dataset\n",
    "\n",
    "def get_ordered_cols(dataset, cols, dict_col_params):\n",
    "    for col in cols:\n",
    "        res = get_ordered_col(dataset, col, dict_col_params)\n",
    "    return res.drop(columns=cols)     \n",
    "\n",
    "dict_label_5_1 = {'Ex': 4,'Gd': 3,'TA': 2,'Fa': 1,'Po': 0}\n",
    "dict_label_5_2 = {'Ex': 4,'Gd': 3,'TA': 2,'Fa': 1,'NA': 0}\n",
    "dict_label_5_3 = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0} \n",
    "dict_label_6_1 = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "dict_label_7_1 = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1, 'NA': 0} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция подготовки данных\n",
    "def get_data(dataset):\n",
    "    put_value_to_na_param(dataset, ['MiscFeature','Alley','Fence','BsmtQual','PoolQC','BsmtCond',\\\n",
    "                                    'BsmtExposure','BsmtFinType1','BsmtFinType2','FireplaceQu',\\\n",
    "                                    'GarageType','GarageFinish','GarageQual','GarageCond'], 'NA' )\n",
    "    \n",
    "    put_value_to_na_param(dataset, ['MasVnrArea'], 0)\n",
    "    put_value_to_na_param(dataset, ['MasVnrType'], 'none')                      \n",
    "    put_mean_to_na_param(dataset, ['LotFrontage'])\n",
    "    put_most_common_meaning_to_na_param(dataset, ['Electrical'])   \n",
    "    put_param_from_col_src_to_na_param(dataset, 'GarageYrBlt', 'YearRemodAdd')     \n",
    "    \n",
    "    data_raw = dataset.copy()\n",
    "    data_raw = get_one_hot(dataset, ['MiscFeature', 'Fence', 'Alley', 'Street', 'LotShape', 'LandContour', 'Utilities',\\\n",
    "                                     'LotConfig', 'LandSlope', 'BldgType', 'MasVnrType', 'Foundation', 'Heating', \\\n",
    "                                     'CentralAir', 'Electrical', 'PavedDrive', 'MSZoning','MSSubClass','Neighborhood','Condition1',\\\n",
    "                                     'Condition2','HouseStyle','RoofStyle','RoofMatl','Exterior1st',\\\n",
    "                                     'Exterior2nd','Functional','GarageType','GarageFinish',\\\n",
    "                                     'SaleType','SaleCondition'])\n",
    "    \n",
    "    data_raw = get_ordered_cols(data_raw, ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual'], dict_label_5_1)\n",
    "    data_raw = get_ordered_cols(data_raw, ['PoolQC'], dict_label_5_2)\n",
    "    data_raw = get_ordered_cols(data_raw, ['BsmtExposure'], dict_label_5_3)\n",
    "    data_raw = get_ordered_cols(data_raw, ['BsmtQual', 'BsmtCond', 'FireplaceQu', 'GarageQual', 'GarageCond'] , dict_label_6_1)\n",
    "    data_raw = get_ordered_cols(data_raw, ['BsmtFinType1', 'BsmtFinType2'] , dict_label_7_1) \n",
    "    \n",
    "    y = data_raw['SalePrice'].copy()\n",
    "    #data_raw= data_raw.drop(columns=['SaleCategory'])\n",
    "    columns_to_drop = ['SalePrice', 'MSZoning','MSSubClass','Neighborhood','Condition1',\\\n",
    "                       'Condition2','HouseStyle','RoofStyle','RoofMatl','Exterior1st',\\\n",
    "                       'Exterior2nd','Functional','GarageType','GarageFinish',\\\n",
    "                       'SaleType','SaleCondition','MiscFeature', 'Fence', 'Alley',\\\n",
    "                       'Street', 'LotShape', 'LandContour', 'Utilities',\\\n",
    "                       'LotConfig', 'LandSlope', 'BldgType', 'MasVnrType', \\\n",
    "                       'Foundation', 'Heating', 'CentralAir', 'Electrical', 'PavedDrive']\n",
    "    \n",
    "    data_raw = data_raw.drop(columns=columns_to_drop)\n",
    "    \n",
    "        \n",
    "    \n",
    "    return data_raw, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full, y_full = get_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Columns: 263 entries, Id to BsmtFinType2_order\n",
      "dtypes: float64(2), int64(47), uint8(214)\n",
      "memory usage: 864.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual_order</th>\n",
       "      <th>PoolQC_order</th>\n",
       "      <th>BsmtExposure_order</th>\n",
       "      <th>BsmtQual_order</th>\n",
       "      <th>BsmtCond_order</th>\n",
       "      <th>FireplaceQu_order</th>\n",
       "      <th>GarageQual_order</th>\n",
       "      <th>GarageCond_order</th>\n",
       "      <th>BsmtFinType1_order</th>\n",
       "      <th>BsmtFinType2_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1         65.0     8450            7            5       2003   \n",
       "1   2         80.0     9600            6            8       1976   \n",
       "2   3         68.0    11250            7            5       2001   \n",
       "3   4         60.0     9550            7            5       1915   \n",
       "4   5         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2         ...          \\\n",
       "0          2003       196.0         706           0         ...           \n",
       "1          1976         0.0         978           0         ...           \n",
       "2          2002       162.0         486           0         ...           \n",
       "3          1970         0.0         216           0         ...           \n",
       "4          2000       350.0         655           0         ...           \n",
       "\n",
       "   KitchenQual_order  PoolQC_order  BsmtExposure_order  BsmtQual_order  \\\n",
       "0                  3             0                   1               4   \n",
       "1                  2             0                   4               4   \n",
       "2                  3             0                   2               4   \n",
       "3                  3             0                   1               3   \n",
       "4                  3             0                   3               4   \n",
       "\n",
       "   BsmtCond_order  FireplaceQu_order  GarageQual_order  GarageCond_order  \\\n",
       "0               3                  0                 3                 3   \n",
       "1               3                  3                 3                 3   \n",
       "2               3                  3                 3                 3   \n",
       "3               4                  4                 3                 3   \n",
       "4               3                  3                 3                 3   \n",
       "\n",
       "   BsmtFinType1_order  BsmtFinType2_order  \n",
       "0                   6                   1  \n",
       "1                   5                   1  \n",
       "2                   6                   1  \n",
       "3                   5                   1  \n",
       "4                   6                   1  \n",
       "\n",
       "[5 rows x 263 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X и y общая выборка для моделей 1 уровня \n",
    "# X_out,y_out - выборка для проверки модели второго уровня\n",
    "\n",
    "X, X_out, y, y_out = train_test_split(X_full.drop(columns=['Id']), y_full.values, test_size=0.1 ,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(X)\n",
    "X_keys = X.columns\n",
    "X = sc.transform(X)\n",
    "X_out = sc.transform(X_out)\n",
    "X = pd.DataFrame(X, columns=X_keys)\n",
    "X_out = pd.DataFrame(X_out, columns=X_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Построить случайный лес, вывести важность признаков\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757689406667408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('OverallQual', 0.5264482678244882),\n",
       " ('GrLivArea', 0.11250606766573341),\n",
       " ('GarageCars', 0.050224938049695925),\n",
       " ('TotalBsmtSF', 0.049715846687454074),\n",
       " ('2ndFlrSF', 0.041714517808706074),\n",
       " ('BsmtFinSF1', 0.024674303855184453),\n",
       " ('1stFlrSF', 0.02258822823839033),\n",
       " ('YearBuilt', 0.013063641255038916),\n",
       " ('LotArea', 0.011605307725973344),\n",
       " ('FullBath', 0.011296898344758447),\n",
       " ('GarageArea', 0.010431978703686859),\n",
       " ('FireplaceQu_order', 0.00970786414634318),\n",
       " ('LotFrontage', 0.008672064673418337),\n",
       " ('KitchenQual_order', 0.008152220274634454),\n",
       " ('BsmtQual_order', 0.005282337492803041),\n",
       " ('BsmtUnfSF', 0.005016187633810574),\n",
       " ('MasVnrArea', 0.00417066714873981),\n",
       " ('GarageYrBlt', 0.003913792943300662),\n",
       " ('OpenPorchSF', 0.0038467869649789627),\n",
       " ('MoSold', 0.0036614479329417937)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor()\n",
    "reg.fit(X,y)\n",
    "print(reg.score(X,y))\n",
    "\n",
    "feature_importances= {}\n",
    "for col, val in zip(X.columns, reg.feature_importances_):\n",
    "    feature_importances[col] = val\n",
    "    \n",
    "sorted_x = sorted(feature_importances.items(), key=lambda kv: kv[1], reverse=True)\n",
    "sorted_x[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Обучить стекинг как минимум 3х моделей, использовать \n",
    "#    хотя бы 1 линейную модель и 1 нелинейную\n",
    "# 5. Для валидации модели 2-го уровня использовать \n",
    "#    отдельный hold-out датасет, как на занятии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для стекинга используем следующие типы моделей\n",
    "# модели первого уровня\n",
    "# 1. SGDRegressor\n",
    "# 2. Ridge\n",
    "# 3. KNeighborsRegressor\n",
    "# модель второго уровня\n",
    "# 1. LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ARDRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAX(data):\n",
    "    data_max = data.copy()\n",
    "    keys = data_max.keys()\n",
    "    for key1 in keys:\n",
    "        for key2 in keys:\n",
    "            data_max[key1+'_x_'+key2] = data_max[key1]*data_max[key2]\n",
    "    return data_max.drop(columns=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stacking(X, y, dict_model, meta_model, param_model_GS, param_meta_model, make_max = False):\n",
    "    # получаем длину фолда\n",
    "    len_fold = (len(X) // len(dict_model.keys()))+1\n",
    "    kf = KFold(n_splits=len(dict_model.keys()), shuffle=True)\n",
    "    result_fold = {}\n",
    "    i = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        test_index_l = list(test_index)\n",
    "        train_index_l =  list(train_index)\n",
    "        # для того что бы данные для мета модели были полные\n",
    "        # выравниваем длину фолдов\n",
    "        # переносим избыток индексов из train в test\n",
    "        if(len_fold > len(test_index)):\n",
    "            # получим номера индексов в train  для переноса в test   \n",
    "            add_num = random.sample(range(len(train_index)), len_fold > len(test_index))\n",
    "            # получим индексы из train\n",
    "            list_change_elem = train_index[add_num]\n",
    "            # пройдем по списку индексов \n",
    "            for k in list_change_elem:\n",
    "                # удалим индекс из train\n",
    "                train_index_l.remove(k)\n",
    "                #  добавим индекс в test\n",
    "                test_index_l = test_index_l + list([k,])\n",
    "        # -----------------------        \n",
    "        # формируем выборки данных для фолдов\n",
    "        k = list(dict_model.keys())[i]\n",
    "        result_fold[k] = {'X_train': X.iloc[train_index_l], 'X_test': X.iloc[test_index_l],\n",
    "                          'y_train': y[train_index_l], 'y_test': y[test_index_l]}\n",
    "        # ------------------------\n",
    "        i+=1\n",
    "    result_model ={}\n",
    "    # проходим по списку моделей 1 уровня \n",
    "    print('stacking')\n",
    "    for j in dict_model.keys():\n",
    "        # обучаем \n",
    "        dict_model[j] = GridSearchCV(dict_model[j], param_model_GS[j], cv=5, n_jobs=-1).fit(result_fold[j]['X_train'], result_fold[j]['y_train']).best_estimator_\n",
    "        # предсказания помещаем в словарь с данными для мета модели\n",
    "        result_model[j] = dict_model[j].predict(result_fold[j]['X_test'])\n",
    "        print('MAE ', j, \":\",mean_absolute_error(result_model[j], result_fold[j]['y_test']))\n",
    "    df_result = pd.DataFrame.from_dict(result_model)\n",
    "    # обучаем мета модел\n",
    "    df_result_2 = get_MAX(df_result) if make_max else df_result\n",
    "    meta_model_best =  GridSearchCV(meta_model, param_meta_model, cv=5, n_jobs=-1).fit(df_result_2,result_fold[j]['y_test']).best_estimator_\n",
    "    print('MAE stacking:',mean_absolute_error(meta_model_best.predict(df_result_2), result_fold[j]['y_test']))\n",
    "    return dict_model, meta_model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_blanding(X, y, dict_model, meta_model,param_model_GS, param_meta_model, make_max = False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
    "    result_model ={}\n",
    "    print('blanding')\n",
    "    for i in dict_model.keys():\n",
    "        dict_model[i] = GridSearchCV(dict_model[i], param_model_GS[i], cv=5, n_jobs=-1).fit(X_train, y_train).best_estimator_\n",
    "        result_model[i] = dict_model[i].predict(X_test)\n",
    "        print('MAE ', i, \":\",mean_absolute_error(result_model[i], y_test))\n",
    "    df_result = pd.DataFrame.from_dict(result_model)\n",
    "    df_result_2 = get_MAX(df_result) if make_max else df_result\n",
    "    meta_model_best = GridSearchCV(meta_model, param_meta_model, cv=5, n_jobs=-1).fit(df_result_2,y_test).best_estimator_\n",
    "    print('MAE blanding:',mean_absolute_error(meta_model_best.predict(df_result_2), y_test))\n",
    "    return dict_model, meta_model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_result(X, dict_model, meta_model, make_max = False ):\n",
    "    result_model ={}\n",
    "    for i in dict_model.keys():\n",
    "        result_model[i] = dict_model[i].predict(X)\n",
    "    df_result = pd.DataFrame.from_dict(result_model)\n",
    "    df_result_2 = get_MAX(df_result) if make_max else df_result\n",
    "    result = meta_model.predict(df_result_2) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanding\n",
      "MAE  KNeighborsRegressor : 26231.96600361664\n",
      "MAE  Ridge : 19903.10481211439\n",
      "MAE  Lasso : 19791.901001248203\n",
      "MAE  LinearSVR : 23783.662911215048\n",
      "MAE  DecisionTreeRegressor : 28118.022873764745\n",
      "MAE blanding: 18045.44571364402\n",
      "stacking\n",
      "MAE  KNeighborsRegressor : 23855.769328263625\n",
      "MAE  Ridge : 17539.18507562447\n",
      "MAE  Lasso : 19954.035711675737\n",
      "MAE  LinearSVR : 24783.966184263645\n",
      "MAE  DecisionTreeRegressor : 27476.722034030103\n",
      "MAE stacking: 27525.572649960097\n"
     ]
    }
   ],
   "source": [
    "param_model_GS = {'Ridge':{'alpha':[0.1,0.5,1]}, \n",
    "              'Lasso':{'alpha':[0.1,0.5,1]}, \n",
    "              'KNeighborsRegressor':{'n_neighbors':[3,5,7,9]},\n",
    "              'LinearSVR':{'C':[0.1,0.5,1], 'loss':['epsilon_insensitive', 'squared_epsilon_insensitive']},\n",
    "              'DecisionTreeRegressor':{'max_depth':[3,5,7,9]},                                    \n",
    "              'LinearRegression':{},\n",
    "              'SGDRegressor':{'loss':['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "                              'penalty':['none', 'l2', 'l1','elasticnet'] \n",
    "                             },\n",
    "              'ARDRegression':{'alpha_1':[0.0000001,0.000001,0.00001,],'lambda_1':[0.0000001,0.000001,0.00001,]}   \n",
    "             }\n",
    "\n",
    "\n",
    "\n",
    "dict_model = {}\n",
    "dict_model['KNeighborsRegressor'] = KNeighborsRegressor()\n",
    "dict_model['Ridge'] = Ridge()\n",
    "dict_model['Lasso'] = Lasso()\n",
    "dict_model['LinearSVR'] = LinearSVR()\n",
    "#dict_model['SGDRegressor'] = SGDRegressor()\n",
    "dict_model['DecisionTreeRegressor'] = DecisionTreeRegressor()\n",
    "#dict_model['LinearRegression'] = LinearRegression()\n",
    "meta_model = ARDRegression()\n",
    "\n",
    "\n",
    "blending_dict_model, blending_meta_model = make_blanding(X, y, dict_model, meta_model,param_model_GS, param_model_GS['ARDRegression'])\n",
    "blending_result = predict_result(X_out, blending_dict_model, blending_meta_model)\n",
    "\n",
    "stacking_dict_model, stacking_meta_model = make_stacking(X, y, dict_model, meta_model,param_model_GS, param_model_GS['ARDRegression'])\n",
    "stacking_result = predict_result(X_out, stacking_dict_model, stacking_meta_model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DecisionTreeRegressor': DecisionTreeRegressor(criterion='mse', max_depth=9, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       " 'KNeighborsRegressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='uniform'),\n",
       " 'Lasso': Lasso(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=None,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'LinearSVR': LinearSVR(C=0.1, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "      intercept_scaling=1.0, loss='squared_epsilon_insensitive',\n",
       "      max_iter=1000, random_state=None, tol=0.0001, verbose=0),\n",
       " 'Ridge': Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=None, solver='auto', tol=0.001)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending_dict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравнение моделей\n",
    "# для сравнения используем все простые модели используемые в ансамблировании\n",
    "# и ансамблевые модели представленные в sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "param_model_GS['RandomForestRegressor'] = {'max_depth':[3,5,7,9]}\n",
    "param_model_GS['BaggingRegressor'] = {'base_estimator':[Ridge(), Lasso()] }\n",
    "param_model_GS['GradientBoostingRegressor'] = {'loss' : ['ls', 'lad', 'huber', 'quantile']}\n",
    "param_model_GS['AdaBoostRegressor'] = {'loss' : ['linear', 'square', 'exponential'],'base_estimator':[Ridge(), Lasso(), None] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Rg  = GridSearchCV(Ridge(), param_model_GS['Ridge'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "Ls  = GridSearchCV(Lasso(), param_model_GS['Lasso'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "KNR = GridSearchCV(KNeighborsRegressor(), param_model_GS['KNeighborsRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "SVR = GridSearchCV(LinearSVR(), param_model_GS['LinearSVR'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "DTR = GridSearchCV(DecisionTreeRegressor(), param_model_GS['DecisionTreeRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "SGD = GridSearchCV(SGDRegressor(), param_model_GS['SGDRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "LR  = LinearRegression().fit(X,y).predict(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = GridSearchCV(RandomForestRegressor(), param_model_GS['RandomForestRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "BR  = GridSearchCV(BaggingRegressor(), param_model_GS['BaggingRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "GBR = GridSearchCV(GradientBoostingRegressor(), param_model_GS['GradientBoostingRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)\n",
    "ABR = GridSearchCV(AdaBoostRegressor(), param_model_GS['AdaBoostRegressor'], cv=5, n_jobs=-1).fit(X,y).best_estimator_.predict(X_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blending: 20803.113328631985\n",
      "stacking: 23381.801057183777\n",
      "ridge   : 20333.968734261707\n",
      "lasso   : 20514.189099687002\n",
      "KNR     : 27300.959665144597\n",
      "SVR     : 20280.540700349447\n",
      "DTR     : 20104.89371316692\n",
      "SGD     : 182859.6699776689\n",
      "LR      : 1284451250444319.5\n",
      "RFR     : 18094.231185598113\n",
      "BR      : 19598.48365304687\n",
      "GBR     : 15241.677938146157\n",
      "ABR     : 22901.66109759587\n"
     ]
    }
   ],
   "source": [
    "print('blending:', mean_absolute_error(blending_result,y_out))\n",
    "print('stacking:', mean_absolute_error(stacking_result,y_out))\n",
    "print('ridge   :', mean_absolute_error(Rg,y_out))\n",
    "print('lasso   :', mean_absolute_error(Ls,y_out))\n",
    "print('KNR     :', mean_absolute_error(KNR,y_out))\n",
    "print('SVR     :', mean_absolute_error(SVR,y_out))\n",
    "print('DTR     :', mean_absolute_error(DTR,y_out))\n",
    "print('SGD     :', mean_absolute_error(SGD,y_out))\n",
    "print('LR      :', mean_absolute_error(LR,y_out))\n",
    "print('RFR     :', mean_absolute_error(RFR,y_out))\n",
    "print('BR      :', mean_absolute_error(BR,y_out))\n",
    "print('GBR     :', mean_absolute_error(GBR,y_out))\n",
    "print('ABR     :', mean_absolute_error(ABR,y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blending: 0.842182885301606\n",
      "stacking: 0.8384602064042123\n",
      "ridge   : 0.8605925614126352\n",
      "lasso   : 0.8604944146358682\n",
      "KNR     : 0.2301631689014455\n",
      "SVR     : 0.8596783338475624\n",
      "DTR     : 0.8692136696723076\n",
      "SGD     : -143266804255.90283\n",
      "LR      : -0.0005560992373536688\n",
      "RFR     : 0.8149751394507361\n",
      "BR      : 0.8618133837446534\n",
      "GBR     : 0.8853853928363336\n",
      "ABR     : 0.7813089745523257\n"
     ]
    }
   ],
   "source": [
    "print('blending:', r2_score(blending_result,y_out))\n",
    "print('stacking:', r2_score(stacking_result,y_out))\n",
    "print('ridge   :', r2_score(Rg,y_out))\n",
    "print('lasso   :', r2_score(Ls,y_out))\n",
    "print('KNR     :', r2_score(KNR,y_out))\n",
    "print('SVR     :', r2_score(SVR,y_out))\n",
    "print('DTR     :', r2_score(DTR,y_out))\n",
    "print('SGD     :', r2_score(SGD,y_out))\n",
    "print('LR      :', r2_score(LR,y_out))\n",
    "print('RFR     :', r2_score(RFR,y_out))\n",
    "print('BR      :', r2_score(BR,y_out))\n",
    "print('GBR     :', r2_score(GBR,y_out))\n",
    "print('ABR     :', r2_score(ABR,y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение моделей показало, # что такая реализация не увеличивает \n",
    "# качество ответа по сравнению с некотрыми обычными и ансамблевыми моделями\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем различные методики повышения качества стекинга\n",
    "#\n",
    "# 1. Следуя советам данным в https://dyakonov.org/2017/03/10/cтекинг-stacking-и-блендинг-blending \n",
    "#   а) не будем подбирать для моделей гиперпараметры, \n",
    "#      а будем использовать несколько модели одного типа с разным их набором\n",
    "#   б) мета модель будем обучать не на непосредственно полученых признаках,   \n",
    "#      а на сгенерированных с помощью их декартова произведения  \n",
    "#\n",
    "#  2. В качестве моделей возмем \n",
    "#    а) Ridge\n",
    "#    б) Lasso\n",
    "#    б) DecisionTreeRegressor\n",
    "#    б) SVR\n",
    "#    б) KNR\n",
    "#  Каждую из моделей возмем 3-5 вариантах по гиперпараметрам\n",
    "#  В качестве мета модели возмем Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "param_model_GS_2={'Ridge1':{'alpha':[0.01]},\n",
    "                  'Ridge2':{'alpha':[0.05]}, \n",
    "                  'Ridge3':{'alpha':[0.1]}, \n",
    "                  'Ridge4':{'alpha':[0.5]}, \n",
    "                  'Ridge5':{'alpha':[1]},\n",
    "                  'Ridge5':{'alpha':[5]},\n",
    "                  'Lasso1':{'alpha':[0.01]}, \n",
    "                  'Lasso2':{'alpha':[0.05]}, \n",
    "                  'Lasso3':{'alpha':[0.1]}, \n",
    "                  'Lasso4':{'alpha':[0.5]}, \n",
    "                  'Lasso5':{'alpha':[1]},\n",
    "                  'Lasso6':{'alpha':[5]},\n",
    "    'KNeighborsRegressor1':{'n_neighbors':[3]},\n",
    "    'KNeighborsRegressor2':{'n_neighbors':[5]},\n",
    "    'KNeighborsRegressor3':{'n_neighbors':[7]},\n",
    "    'KNeighborsRegressor4':{'n_neighbors':[9]},\n",
    "                    'SVR1':{'kernel':['linear'], 'C':[0.1,0.5,1]},\n",
    "                    'SVR2':{'kernel':['poly'], 'C':[0.1,0.5,1]},\n",
    "                    'SVR3':{'kernel':['rbf'], 'C':[0.1,0.5,1]},\n",
    "                    'SVR4':{'kernel':['sigmoid'], 'C':[0.1,0.5,1]},\n",
    "  'DecisionTreeRegressor1':{'max_depth':[1]},                                   \n",
    "  'DecisionTreeRegressor2':{'max_depth':[3]},                                    \n",
    "  'DecisionTreeRegressor3':{'max_depth':[5]},                                    \n",
    "  'DecisionTreeRegressor4':{'max_depth':[7]},                                    \n",
    "  'DecisionTreeRegressor5':{'max_depth':[9]},                                    \n",
    "             }\n",
    "dict_model_2 = {}\n",
    "dict_model_2['Ridge1'] = Ridge()\n",
    "dict_model_2['Ridge2'] = Ridge()\n",
    "dict_model_2['Ridge3'] = Ridge()\n",
    "dict_model_2['Ridge4'] = Ridge()\n",
    "dict_model_2['Ridge5'] = Ridge()\n",
    "dict_model_2['Ridge5'] = Ridge()\n",
    "dict_model_2['Lasso1'] = Lasso()\n",
    "dict_model_2['Lasso2'] = Lasso()\n",
    "dict_model_2['Lasso3'] = Lasso()\n",
    "dict_model_2['Lasso4'] = Lasso()\n",
    "dict_model_2['Lasso5'] = Lasso()\n",
    "dict_model_2['Lasso6'] = Lasso()\n",
    "dict_model_2['KNeighborsRegressor1'] = KNeighborsRegressor()\n",
    "dict_model_2['KNeighborsRegressor2'] = KNeighborsRegressor()\n",
    "dict_model_2['KNeighborsRegressor3'] = KNeighborsRegressor()\n",
    "dict_model_2['KNeighborsRegressor4'] = KNeighborsRegressor()\n",
    "dict_model_2['SVR1'] = SVR()\n",
    "dict_model_2['SVR2'] = SVR()\n",
    "dict_model_2['SVR3'] = SVR()\n",
    "dict_model_2['SVR4'] = SVR()\n",
    "dict_model_2['DecisionTreeRegressor1'] = DecisionTreeRegressor()\n",
    "dict_model_2['DecisionTreeRegressor2'] = DecisionTreeRegressor()\n",
    "dict_model_2['DecisionTreeRegressor3'] = DecisionTreeRegressor()\n",
    "dict_model_2['DecisionTreeRegressor4'] = DecisionTreeRegressor()\n",
    "dict_model_2['DecisionTreeRegressor5'] = DecisionTreeRegressor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanding\n",
      "MAE  Ridge1 : 21610.447144125865\n",
      "MAE  Ridge2 : 21604.463602500993\n",
      "MAE  Ridge3 : 21597.034455341767\n",
      "MAE  Ridge4 : 21539.507626585633\n",
      "MAE  Ridge5 : 21073.325462342225\n",
      "MAE  Lasso1 : 21999.61337348825\n",
      "MAE  Lasso2 : 21974.07288843056\n",
      "MAE  Lasso3 : 21950.02916311487\n",
      "MAE  Lasso4 : 21906.54937257303\n",
      "MAE  Lasso5 : 21854.56904458646\n",
      "MAE  Lasso6 : 21492.68443049822\n",
      "MAE  KNeighborsRegressor1 : 27078.34936708861\n",
      "MAE  KNeighborsRegressor2 : 26765.514936708863\n",
      "MAE  KNeighborsRegressor3 : 26182.174321880648\n",
      "MAE  KNeighborsRegressor4 : 26199.772995780586\n",
      "MAE  SVR1 : 48262.09987057522\n",
      "MAE  SVR2 : 56895.90039880984\n",
      "MAE  SVR3 : 56880.830365204754\n",
      "MAE  SVR4 : 56863.805782192416\n",
      "MAE  DecisionTreeRegressor1 : 44158.596566529675\n",
      "MAE  DecisionTreeRegressor2 : 33314.06119291947\n",
      "MAE  DecisionTreeRegressor3 : 30190.99766550298\n",
      "MAE  DecisionTreeRegressor4 : 29266.692853775145\n",
      "MAE  DecisionTreeRegressor5 : 27208.11259415961\n",
      "MAE blanding: 18261.45645771932\n",
      "stacking\n",
      "MAE  Ridge1 : 16098.896629925803\n",
      "MAE  Ridge2 : 16994.048282555723\n",
      "MAE  Ridge3 : 17983.660988367545\n",
      "MAE  Ridge4 : 19038.01146034388\n",
      "MAE  Ridge5 : 14603.003653449528\n",
      "MAE  Lasso1 : 15746.019332544834\n",
      "MAE  Lasso2 : 21590.865289276462\n",
      "MAE  Lasso3 : 20941.671281502506\n",
      "MAE  Lasso4 : 20868.574918239774\n",
      "MAE  Lasso5 : 17482.94734751787\n",
      "MAE  Lasso6 : 17313.80165238126\n",
      "MAE  KNeighborsRegressor1 : 39823.88484848484\n",
      "MAE  KNeighborsRegressor2 : 37189.04\n",
      "MAE  KNeighborsRegressor3 : 26726.706493506495\n",
      "MAE  KNeighborsRegressor4 : 37301.49494949495\n",
      "MAE  SVR1 : 38395.32387060698\n",
      "MAE  SVR2 : 50143.068074550225\n",
      "MAE  SVR3 : 69475.31923542346\n",
      "MAE  SVR4 : 55171.56151668393\n",
      "MAE  DecisionTreeRegressor1 : 39373.460955490635\n",
      "MAE  DecisionTreeRegressor2 : 29660.550739704853\n",
      "MAE  DecisionTreeRegressor3 : 27841.977766924592\n",
      "MAE  DecisionTreeRegressor4 : 24599.392059674374\n",
      "MAE  DecisionTreeRegressor5 : 19932.430378904\n",
      "MAE stacking: 16265.652399661054\n"
     ]
    }
   ],
   "source": [
    "blending_dict_model_2, blending_meta_model_2 = make_blanding(X, y, dict_model_2, Ridge(),param_model_GS_2, {'alpha':[0.5,1,5]})\n",
    "blending_result_2 = predict_result(X_out, blending_dict_model_2, blending_meta_model_2)\n",
    "\n",
    "stacking_dict_model_2, stacking_meta_model_2 = make_stacking(X, y, dict_model_2, Ridge(),param_model_GS_2, {'alpha':[0.5,1,5]})   \n",
    "stacking_result_2 = predict_result(X_out, stacking_dict_model_2, stacking_meta_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blending: 21888.07941495229\n",
      "stacking: 36383.55567960053\n",
      "blending: 0.798548476197396\n",
      "stacking: -0.1822211349742895\n"
     ]
    }
   ],
   "source": [
    "print('blending:', mean_absolute_error(blending_result_2,y_out))\n",
    "print('stacking:', mean_absolute_error(stacking_result_2,y_out))\n",
    "\n",
    "print('blending:', r2_score(blending_result_2,y_out))\n",
    "print('stacking:', r2_score(stacking_result_2,y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanding\n",
      "MAE  Ridge1 : 20517.52749657536\n",
      "MAE  Ridge2 : 20514.66684839883\n",
      "MAE  Ridge3 : 20511.107933967727\n",
      "MAE  Ridge4 : 20484.420429224323\n",
      "MAE  Ridge5 : 20285.145771179956\n",
      "MAE  Lasso1 : 20564.502451166758\n",
      "MAE  Lasso2 : 20562.163679281104\n",
      "MAE  Lasso3 : 20559.383096568752\n",
      "MAE  Lasso4 : 20537.05537178594\n",
      "MAE  Lasso5 : 20513.168936926282\n",
      "MAE  Lasso6 : 20417.90556105136\n",
      "MAE  KNeighborsRegressor1 : 27018.383966244728\n",
      "MAE  KNeighborsRegressor2 : 26124.079999999998\n",
      "MAE  KNeighborsRegressor3 : 25390.640144665464\n",
      "MAE  KNeighborsRegressor4 : 25456.52995780591\n",
      "MAE  SVR1 : 44186.08428915427\n",
      "MAE  SVR2 : 52367.03427606273\n",
      "MAE  SVR3 : 52352.01670197039\n",
      "MAE  SVR4 : 52335.28783957428\n",
      "MAE  DecisionTreeRegressor1 : 42764.69752638832\n",
      "MAE  DecisionTreeRegressor2 : 33060.7787770497\n",
      "MAE  DecisionTreeRegressor3 : 27405.38293513473\n",
      "MAE  DecisionTreeRegressor4 : 26743.788224366202\n",
      "MAE  DecisionTreeRegressor5 : 26857.75786993509\n",
      "MAE blanding: 8701.36595620596\n",
      "stacking\n",
      "MAE  Ridge1 : 19650.247164899174\n",
      "MAE  Ridge2 : 22376.07166578287\n",
      "MAE  Ridge3 : 20096.924232607704\n",
      "MAE  Ridge4 : 30954.32915367983\n",
      "MAE  Ridge5 : 24730.881955824738\n",
      "MAE  Lasso1 : 22075.53440559127\n",
      "MAE  Lasso2 : 16101.551259183583\n",
      "MAE  Lasso3 : 20944.61291679107\n",
      "MAE  Lasso4 : 19856.48277095117\n",
      "MAE  Lasso5 : 22112.000077471406\n",
      "MAE  Lasso6 : 14268.7731805134\n",
      "MAE  KNeighborsRegressor1 : 32502.42424242424\n",
      "MAE  KNeighborsRegressor2 : 27512.283636363638\n",
      "MAE  KNeighborsRegressor3 : 22158.381818181817\n",
      "MAE  KNeighborsRegressor4 : 19102.335353535356\n",
      "MAE  SVR1 : 45913.40042864331\n",
      "MAE  SVR2 : 54691.79059956159\n",
      "MAE  SVR3 : 52941.066505224895\n",
      "MAE  SVR4 : 46053.50004868948\n",
      "MAE  DecisionTreeRegressor1 : 43755.0199653769\n",
      "MAE  DecisionTreeRegressor2 : 35450.456050159075\n",
      "MAE  DecisionTreeRegressor3 : 24149.666282011927\n",
      "MAE  DecisionTreeRegressor4 : 25699.38882607568\n",
      "MAE  DecisionTreeRegressor5 : 28762.11779126995\n",
      "MAE stacking: 6.06682574884458e-10\n"
     ]
    }
   ],
   "source": [
    "blending_dict_model_3, blending_meta_model_3 = make_blanding(X, y, dict_model_2, Ridge(),param_model_GS_2, {'alpha':[0.5,1,5]}, True)\n",
    "blending_result_3 = predict_result(X_out, blending_dict_model_3, blending_meta_model_3, True)\n",
    "\n",
    "stacking_dict_model_3, stacking_meta_model_3 = make_stacking(X, y, dict_model_2, Ridge(),param_model_GS_2, {'alpha':[0.5,1,5]}, True)   \n",
    "stacking_result_3 = predict_result(X_out, stacking_dict_model_3, stacking_meta_model_3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blending: 329082.98877160146\n",
      "stacking: 25527.902440918213\n",
      "blending: -0.0037908491608562578\n",
      "stacking: 0.8856849860628366\n"
     ]
    }
   ],
   "source": [
    "print('blending:', mean_absolute_error(blending_result_3,y_out))\n",
    "print('stacking:', mean_absolute_error(stacking_result_3,y_out))\n",
    "\n",
    "print('blending:', r2_score(blending_result_3,y_out))\n",
    "print('stacking:', r2_score(stacking_result_3,y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# судя по результатам можно сделать следующие наблюдения\n",
    "# а) для случая без генерации дополнительных переменных блендинг и стекинг отработали хуже\n",
    "#    наблюдается переобучение \n",
    "# б) для случая с генерацией дополнительных переменных стекинг отработал лучше, \n",
    "#    а блендинг еще сильней переобучился "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
